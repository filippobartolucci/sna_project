{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Analysis"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pyreadr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import seaborn as sns\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tsv file\n",
    "r_body = pd.read_csv('soc-redditHyperlinks-body.tsv', sep='\\t')\n",
    "r_title = pd.read_csv('soc-redditHyperlinks-title.tsv', sep='\\t')\n",
    "\n",
    "# Merge two dataframes\n",
    "r = pd.concat([r_body, r_title])\n",
    "r = r.drop(['PROPERTIES'], axis=1)\n",
    "\n",
    "r_neg = r[r['LINK_SENTIMENT'] == -1]\n",
    "r_pos = r[r['LINK_SENTIMENT'] == 1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>POST_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "      <th>PROPERTIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>teamredditteams</td>\n",
       "      <td>1u4nrps</td>\n",
       "      <td>2013-12-31 16:39:58</td>\n",
       "      <td>1</td>\n",
       "      <td>345.0,298.0,0.75652173913,0.0173913043478,0.08...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>theredlion</td>\n",
       "      <td>soccer</td>\n",
       "      <td>1u4qkd</td>\n",
       "      <td>2013-12-31 18:18:37</td>\n",
       "      <td>-1</td>\n",
       "      <td>101.0,98.0,0.742574257426,0.019801980198,0.049...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inlandempire</td>\n",
       "      <td>bikela</td>\n",
       "      <td>1u4qlzs</td>\n",
       "      <td>2014-01-01 14:54:35</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0,85.0,0.752941176471,0.0235294117647,0.082...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>nfl</td>\n",
       "      <td>cfb</td>\n",
       "      <td>1u4sjvs</td>\n",
       "      <td>2013-12-31 17:37:55</td>\n",
       "      <td>1</td>\n",
       "      <td>1124.0,949.0,0.772241992883,0.0017793594306,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>playmygame</td>\n",
       "      <td>gamedev</td>\n",
       "      <td>1u4w5ss</td>\n",
       "      <td>2014-01-01 02:51:13</td>\n",
       "      <td>1</td>\n",
       "      <td>715.0,622.0,0.777622377622,0.00699300699301,0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  SOURCE_SUBREDDIT TARGET_SUBREDDIT  POST_ID            TIMESTAMP  \\\n",
       "0  leagueoflegends  teamredditteams  1u4nrps  2013-12-31 16:39:58   \n",
       "1       theredlion           soccer   1u4qkd  2013-12-31 18:18:37   \n",
       "2     inlandempire           bikela  1u4qlzs  2014-01-01 14:54:35   \n",
       "3              nfl              cfb  1u4sjvs  2013-12-31 17:37:55   \n",
       "4       playmygame          gamedev  1u4w5ss  2014-01-01 02:51:13   \n",
       "\n",
       "   LINK_SENTIMENT                                         PROPERTIES  \n",
       "0               1  345.0,298.0,0.75652173913,0.0173913043478,0.08...  \n",
       "1              -1  101.0,98.0,0.742574257426,0.019801980198,0.049...  \n",
       "2               1  85.0,85.0,0.752941176471,0.0235294117647,0.082...  \n",
       "3               1  1124.0,949.0,0.772241992883,0.0017793594306,0....  \n",
       "4               1  715.0,622.0,0.777622377622,0.00699300699301,0....  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_body.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>POST_ID</th>\n",
       "      <th>TIMESTAMP</th>\n",
       "      <th>LINK_SENTIMENT</th>\n",
       "      <th>PROPERTIES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>517657</th>\n",
       "      <td>gamedev</td>\n",
       "      <td>indiegaming</td>\n",
       "      <td>5rvv2fs</td>\n",
       "      <td>2017-02-03 11:02:52</td>\n",
       "      <td>1</td>\n",
       "      <td>108.0,92.0,0.787037037037,0.0,0.138888888889,0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170517</th>\n",
       "      <td>goldredditsays</td>\n",
       "      <td>videos</td>\n",
       "      <td>31vd51s</td>\n",
       "      <td>2015-04-09 05:23:18</td>\n",
       "      <td>1</td>\n",
       "      <td>78.0,70.0,0.692307692308,0.0512820512821,0.089...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>515338</th>\n",
       "      <td>shitthe_donaldsays</td>\n",
       "      <td>trumpforprison</td>\n",
       "      <td>5r6cq0s</td>\n",
       "      <td>2017-01-30 21:37:31</td>\n",
       "      <td>1</td>\n",
       "      <td>94.0,84.0,0.808510638298,0.0212765957447,0.063...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22050</th>\n",
       "      <td>switcharoo</td>\n",
       "      <td>mapporn</td>\n",
       "      <td>20a8fcs</td>\n",
       "      <td>2014-03-12 19:08:28</td>\n",
       "      <td>1</td>\n",
       "      <td>40.0,35.0,0.8,0.0,0.2,0.15,0.05,7.0,7.0,1.0,4....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417487</th>\n",
       "      <td>switcharoo</td>\n",
       "      <td>oddlysatisfying</td>\n",
       "      <td>4x5pszs</td>\n",
       "      <td>2016-08-11 01:03:34</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0,24.0,0.814814814815,0.0,0.296296296296,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>531910</th>\n",
       "      <td>kappa</td>\n",
       "      <td>fighters</td>\n",
       "      <td>5wgssqs</td>\n",
       "      <td>2017-02-27 05:40:53</td>\n",
       "      <td>1</td>\n",
       "      <td>109.0,91.0,0.798165137615,0.00917431192661,0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237923</th>\n",
       "      <td>drugs</td>\n",
       "      <td>netsec</td>\n",
       "      <td>3hyyzss</td>\n",
       "      <td>2015-08-22 08:08:53</td>\n",
       "      <td>1</td>\n",
       "      <td>85.0,72.0,0.788235294118,0.0,0.141176470588,0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318472</th>\n",
       "      <td>negativewithgold</td>\n",
       "      <td>quityourbullshit</td>\n",
       "      <td>43d10ps</td>\n",
       "      <td>2016-01-30 08:08:20</td>\n",
       "      <td>1</td>\n",
       "      <td>53.0,45.0,0.660377358491,0.0377358490566,0.113...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83222</th>\n",
       "      <td>samneill</td>\n",
       "      <td>funny</td>\n",
       "      <td>2fb052s</td>\n",
       "      <td>2014-09-04 07:39:58</td>\n",
       "      <td>1</td>\n",
       "      <td>63.0,57.0,0.84126984127,0.0,0.142857142857,0.1...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>375104</th>\n",
       "      <td>bedrocklinux</td>\n",
       "      <td>asklinuxusers</td>\n",
       "      <td>4keqxas</td>\n",
       "      <td>2016-05-21 11:17:14</td>\n",
       "      <td>1</td>\n",
       "      <td>44.0,40.0,0.818181818182,0.0,0.295454545455,0....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          SOURCE_SUBREDDIT  TARGET_SUBREDDIT  POST_ID            TIMESTAMP  \\\n",
       "517657             gamedev       indiegaming  5rvv2fs  2017-02-03 11:02:52   \n",
       "170517      goldredditsays            videos  31vd51s  2015-04-09 05:23:18   \n",
       "515338  shitthe_donaldsays    trumpforprison  5r6cq0s  2017-01-30 21:37:31   \n",
       "22050           switcharoo           mapporn  20a8fcs  2014-03-12 19:08:28   \n",
       "417487          switcharoo   oddlysatisfying  4x5pszs  2016-08-11 01:03:34   \n",
       "531910               kappa          fighters  5wgssqs  2017-02-27 05:40:53   \n",
       "237923               drugs            netsec  3hyyzss  2015-08-22 08:08:53   \n",
       "318472    negativewithgold  quityourbullshit  43d10ps  2016-01-30 08:08:20   \n",
       "83222             samneill             funny  2fb052s  2014-09-04 07:39:58   \n",
       "375104        bedrocklinux     asklinuxusers  4keqxas  2016-05-21 11:17:14   \n",
       "\n",
       "        LINK_SENTIMENT                                         PROPERTIES  \n",
       "517657               1  108.0,92.0,0.787037037037,0.0,0.138888888889,0...  \n",
       "170517               1  78.0,70.0,0.692307692308,0.0512820512821,0.089...  \n",
       "515338               1  94.0,84.0,0.808510638298,0.0212765957447,0.063...  \n",
       "22050                1  40.0,35.0,0.8,0.0,0.2,0.15,0.05,7.0,7.0,1.0,4....  \n",
       "417487               1  27.0,24.0,0.814814814815,0.0,0.296296296296,0....  \n",
       "531910               1  109.0,91.0,0.798165137615,0.00917431192661,0.1...  \n",
       "237923               1  85.0,72.0,0.788235294118,0.0,0.141176470588,0....  \n",
       "318472               1  53.0,45.0,0.660377358491,0.0377358490566,0.113...  \n",
       "83222                1  63.0,57.0,0.84126984127,0.0,0.142857142857,0.1...  \n",
       "375104               1  44.0,40.0,0.818181818182,0.0,0.295454545455,0....  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_title.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of positive and negative links in title\n",
      " 1    0.893098\n",
      "-1    0.106902\n",
      "Name: LINK_SENTIMENT, dtype: float64\n",
      "\n",
      "Percentage of positive and negative links in body\n",
      " 1    0.926473\n",
      "-1    0.073527\n",
      "Name: LINK_SENTIMENT, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Percentage of positive and negative links in title\")\n",
    "print(r_title['LINK_SENTIMENT'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nPercentage of positive and negative links in body\")\n",
    "print(r_body['LINK_SENTIMENT'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability that a negative link is in the body\n",
      "0.2562948546405547\n",
      "Probability that a positive link is in the title\n",
      "6.213197907797105\n"
     ]
    }
   ],
   "source": [
    "# probability that a negative link is in the body\n",
    "print(\"Probability that a negative link is in the body\")\n",
    "print(len(r_body[r_body['LINK_SENTIMENT'] == -1]) / len(r_neg))\n",
    "\n",
    "# probability that a positive link is in the title\n",
    "print(\"Probability that a positive link is in the title\")\n",
    "print(len(r_title[r_title['LINK_SENTIMENT'] == 1]) / len(r_neg))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Subreddit similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "subreddit_embeddings = pyreadr.read_r('subredsimdata.rdata')\n",
    "subreddit_embeddings = pd.DataFrame(subreddit_embeddings[\"subsimmat\"])\n",
    "\n",
    "cosine_sim = cosine_similarity(subreddit_embeddings, subreddit_embeddings)\n",
    "indices = pd.Series(subreddit_embeddings.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def similarity_score(sub1, sub2):\n",
    "    if sub1 not in indices.values or sub2 not in indices.values:\n",
    "        return np.nan\n",
    "    idx1 = indices[indices == sub1].index[0]\n",
    "    idx2 = indices[indices == sub2].index[0]\n",
    "    return cosine_sim[idx1][idx2]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in negative graph:  12069\n",
      "Number of nodes in positive graph:  65892\n",
      "Number of nodes in total graph:  67180\n"
     ]
    }
   ],
   "source": [
    "# get graph with networkx\n",
    "G_neg = nx.from_pandas_edgelist(r_neg, 'SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT',edge_attr='LINK_SENTIMENT', create_using=nx.DiGraph())\n",
    "G_pos = nx.from_pandas_edgelist(r_pos, 'SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT',edge_attr='LINK_SENTIMENT', create_using=nx.DiGraph())\n",
    "G = nx.from_pandas_edgelist(r, 'SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT',edge_attr='LINK_SENTIMENT', create_using=nx.DiGraph())\n",
    "\n",
    "# remove self loop\n",
    "G_neg.remove_edges_from(nx.selfloop_edges(G_neg))\n",
    "G_pos.remove_edges_from(nx.selfloop_edges(G_pos))\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "# remove nodes with degree 0\n",
    "G_neg.remove_nodes_from(list(nx.isolates(G_neg)))\n",
    "G_pos.remove_nodes_from(list(nx.isolates(G_pos)))\n",
    "G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "# print number of nodes\n",
    "print('Number of nodes in negative graph: ', G_neg.number_of_nodes())\n",
    "print('Number of nodes in positive graph: ', G_pos.number_of_nodes())\n",
    "print('Number of nodes in total graph: ', G.number_of_nodes())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Max degree of negative graph:  2056\n",
      "Max degree of positive graph:  5504\n",
      "Max degree of total graph:  5811\n"
     ]
    }
   ],
   "source": [
    "deg_neg = dict(G_neg.degree())\n",
    "deg_pos = dict(G_pos.degree())\n",
    "deg = dict(G.degree())\n",
    "\n",
    "max_deg_neg = max(deg_neg.values())\n",
    "max_deg_pos = max(deg_pos.values())\n",
    "max_deg = max(deg.values())\n",
    "\n",
    "print('\\nMax degree of negative graph: ', max_deg_neg)\n",
    "print('Max degree of positive graph: ', max_deg_pos)\n",
    "print('Max degree of total graph: ', max_deg)\n",
    "\n",
    "# out degree\n",
    "out_deg_neg = dict(G_neg.out_degree())\n",
    "out_deg_pos = dict(G_pos.out_degree())\n",
    "out_deg = dict(G.out_degree())\n",
    "\n",
    "# in degree\n",
    "in_deg_neg = dict(G_neg.in_degree())\n",
    "in_deg_pos = dict(G_pos.in_degree())\n",
    "in_deg = dict(G.in_degree())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total unique nodes:  67180\n",
      "nodes with out degree neg > 10:  0.00821673116999107\n",
      "nodes with in degree neg > 10:  0.009749925573087228\n"
     ]
    }
   ],
   "source": [
    "# sort out degree\n",
    "out_deg_neg = {k: v for k, v in sorted(out_deg_neg.items(), key=lambda item: item[1], reverse=True)}\n",
    "out_deg_pos = {k: v for k, v in sorted(out_deg_pos.items(), key=lambda item: item[1], reverse=True)}\n",
    "out_deg = {k: v for k, v in sorted(out_deg.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "in_deg_neg = {k: v for k, v in sorted(in_deg_neg.items(), key=lambda item: item[1], reverse=True)}\n",
    "in_deg_pos = {k: v for k, v in sorted(in_deg_pos.items(), key=lambda item: item[1], reverse=True)}\n",
    "in_deg = {k: v for k, v in sorted(in_deg.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "print(\"total unique nodes: \", len(set(list(out_deg_neg.keys()) + list(out_deg_pos.keys()) + list(out_deg.keys()))))\n",
    "print(\"nodes with out degree neg > 10: \", len([x for x in out_deg_neg.values() if x > 10])/len(out_deg))\n",
    "print(\"nodes with in degree neg > 10: \", len([x for x in in_deg_neg.values() if x > 10])/len(out_deg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mean out degree of negative graph:  3.411218825089071\n",
      "Mean out degree of positive graph:  4.879788138165483\n",
      "Mean out degree of total graph:  5.055715986900863\n"
     ]
    }
   ],
   "source": [
    "# mean out degree\n",
    "mean_out_deg_neg = np.mean(list(out_deg_neg.values()))\n",
    "mean_out_deg_pos = np.mean(list(out_deg_pos.values()))\n",
    "mean_out_deg = np.mean(list(out_deg.values()))\n",
    "\n",
    "print('\\nMean out degree of negative graph: ', mean_out_deg_neg)\n",
    "print('Mean out degree of positive graph: ', mean_out_deg_pos)\n",
    "print('Mean out degree of total graph: ', mean_out_deg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "first 10 nodes with highest out degree in negative graph\n",
      "\t subredditdrama 1759\n",
      "\t bestof 1091\n",
      "\t drama 839\n",
      "\t botsrights 385\n",
      "\t circlebroke2 361\n",
      "\t shitpost 337\n",
      "\t shitredditsays 293\n",
      "\t shitliberalssay 278\n",
      "\t shitamericanssay 273\n",
      "\t the_donald 255\n",
      "\n",
      "first 10 nodes with highest out degree in positive graph\n",
      "\t bestof 2881\n",
      "\t subredditdrama 2541\n",
      "\t titlegore 2466\n",
      "\t drama 1091\n",
      "\t hailcorporate 907\n",
      "\t switcharoo 901\n",
      "\t shitredditsays 873\n",
      "\t gaming 774\n",
      "\t shitamericanssay 747\n",
      "\t the_donald 716\n",
      "\n",
      "first 10 nodes with highest out degree in total graph\n",
      "\t bestof 3111\n",
      "\t subredditdrama 3020\n",
      "\t titlegore 2469\n",
      "\t drama 1413\n",
      "\t hailcorporate 939\n",
      "\t shitredditsays 923\n",
      "\t switcharoo 918\n",
      "\t the_donald 798\n",
      "\t shitamericanssay 793\n",
      "\t botsrights 792\n",
      "\n",
      "first 10 nodes with highest in degree in negative graph\n",
      "\t askreddit 1108\n",
      "\t funny 506\n",
      "\t pics 500\n",
      "\t worldnews 489\n",
      "\t videos 472\n",
      "\t todayilearned 460\n",
      "\t news 445\n",
      "\t iama 390\n",
      "\t adviceanimals 332\n",
      "\t politics 311\n",
      "\n",
      "first 10 nodes with highest in degree in positive graph\n",
      "\t askreddit 5165\n",
      "\t iama 4404\n",
      "\t pics 3193\n",
      "\t funny 2853\n",
      "\t videos 2500\n",
      "\t todayilearned 2463\n",
      "\t gaming 1673\n",
      "\t worldnews 1626\n",
      "\t gifs 1508\n",
      "\t news 1464\n",
      "\n",
      "first 10 nodes with highest in degree in total graph\n",
      "\t askreddit 5448\n",
      "\t iama 4508\n",
      "\t pics 3335\n",
      "\t funny 3031\n",
      "\t videos 2644\n",
      "\t todayilearned 2589\n",
      "\t worldnews 1770\n",
      "\t gaming 1746\n",
      "\t news 1610\n",
      "\t gifs 1591\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nfirst 10 nodes with highest out degree in negative graph\")\n",
    "for i in range(10):\n",
    "    print(\"\\t\", list(out_deg_neg.keys())[i], list(out_deg_neg.values())[i])\n",
    "\n",
    "print(\"\\nfirst 10 nodes with highest out degree in positive graph\")\n",
    "for i in range(10):\n",
    "    print(\"\\t\", list(out_deg_pos.keys())[i], list(out_deg_pos.values())[i])\n",
    "\n",
    "print(\"\\nfirst 10 nodes with highest out degree in total graph\")\n",
    "for i in range(10):\n",
    "    print(\"\\t\", list(out_deg.keys())[i], list(out_deg.values())[i])\n",
    "\n",
    "print(\"\\nfirst 10 nodes with highest in degree in negative graph\")\n",
    "for i in range(10):\n",
    "    print(\"\\t\", list(in_deg_neg.keys())[i], list(in_deg_neg.values())[i])\n",
    "\n",
    "print(\"\\nfirst 10 nodes with highest in degree in positive graph\")\n",
    "for i in range(10):\n",
    "    print(\"\\t\", list(in_deg_pos.keys())[i], list(in_deg_pos.values())[i])\n",
    "\n",
    "print(\"\\nfirst 10 nodes with highest in degree in total graph\")\n",
    "for i in range(10):\n",
    "    print(\"\\t\", list(in_deg.keys())[i], list(in_deg.values())[i])\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conflicts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31082</th>\n",
       "      <td>shitredditsays</td>\n",
       "      <td>twoxchromosomes</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34945</th>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>relationships</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14431</th>\n",
       "      <td>evenwithcontext</td>\n",
       "      <td>askreddit</td>\n",
       "      <td>97</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1102</th>\n",
       "      <td>amrsucks</td>\n",
       "      <td>againstmensrights</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33765</th>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>askreddit</td>\n",
       "      <td>88</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34837</th>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>pics</td>\n",
       "      <td>85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32907</th>\n",
       "      <td>srssucks</td>\n",
       "      <td>shitredditsays</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35219</th>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35314</th>\n",
       "      <td>subredditdrama</td>\n",
       "      <td>videos</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9006</th>\n",
       "      <td>circlebroke2</td>\n",
       "      <td>pics</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      SOURCE_SUBREDDIT   TARGET_SUBREDDIT  counts\n",
       "31082   shitredditsays    twoxchromosomes     120\n",
       "34945   subredditdrama      relationships     100\n",
       "14431  evenwithcontext          askreddit      97\n",
       "1102          amrsucks  againstmensrights      89\n",
       "33765   subredditdrama          askreddit      88\n",
       "34837   subredditdrama               pics      85\n",
       "32907         srssucks     shitredditsays      79\n",
       "35219   subredditdrama      todayilearned      79\n",
       "35314   subredditdrama             videos      78\n",
       "9006      circlebroke2               pics      77"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conflicts = r_neg.groupby(['SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT']).size().reset_index(name='counts')\n",
    "conflicts = conflicts.sort_values(by=['counts'], ascending=False)\n",
    "conflicts = conflicts[conflicts['counts'] > 10]\n",
    "conflicts.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of nodes in conflict:  530\n",
      "Number of nodes in total graph:  67180\n",
      "Percentage of nodes in conflict:  0.007889252753795772\n",
      "\n",
      "Number of attacker nodes:  240\n",
      "Number of nodes in total graph:  67180\n",
      "Percentage of attacker nodes:  0.003572491813039595\n",
      "\n",
      "Number of attacked nodes:  365\n",
      "Number of nodes in total graph:  67180\n",
      "Percentage of attacked nodes:  0.005433164632331051\n",
      "\n",
      "Number of attacker nodes that are also attacked:  75\n",
      "Number of attacker nodes:  240\n",
      "Percentage of attacker nodes that are also attacked:  0.3125\n"
     ]
    }
   ],
   "source": [
    "# % of nodes that are in conflict \n",
    "node_in_conflicts = set(conflicts[\"SOURCE_SUBREDDIT\"].unique()).union(set(conflicts[\"TARGET_SUBREDDIT\"].unique()))\n",
    "print('Number of nodes in conflict: ', len(node_in_conflicts))\n",
    "print('Number of nodes in total graph: ', G.number_of_nodes())\n",
    "print('Percentage of nodes in conflict: ', len(node_in_conflicts)/G.number_of_nodes())\n",
    "\n",
    "attacker_nodes = set(conflicts[\"SOURCE_SUBREDDIT\"].unique())\n",
    "print('\\nNumber of attacker nodes: ', len(attacker_nodes))\n",
    "print('Number of nodes in total graph: ', G.number_of_nodes())\n",
    "print('Percentage of attacker nodes: ', len(attacker_nodes)/G.number_of_nodes())\n",
    "\n",
    "attacked_nodes = set(conflicts[\"TARGET_SUBREDDIT\"].unique())\n",
    "print('\\nNumber of attacked nodes: ', len(attacked_nodes))\n",
    "print('Number of nodes in total graph: ', G.number_of_nodes())\n",
    "print('Percentage of attacked nodes: ', len(attacked_nodes)/G.number_of_nodes())\n",
    "\n",
    "# % of attacker nodes that are also attacked\n",
    "print('\\nNumber of attacker nodes that are also attacked: ', len(attacker_nodes.intersection(attacked_nodes)))\n",
    "print('Number of attacker nodes: ', len(attacker_nodes))\n",
    "print('Percentage of attacker nodes that are also attacked: ', len(attacker_nodes.intersection(attacked_nodes))/len(attacker_nodes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_conflicts = nx.from_pandas_edgelist(conflicts, 'SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT', edge_attr='counts', create_using=nx.DiGraph())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity score of conflict edges:  0.3512435193020667\n"
     ]
    }
   ],
   "source": [
    "# for each couple in conflict, get similarity\n",
    "conflict_similarities = []\n",
    "for edge in G_conflicts.edges():\n",
    "    score = similarity_score(edge[0], edge[1])\n",
    "    if score > 0:\n",
    "        conflict_similarities.append((edge[0], edge[1], score))\n",
    "\n",
    "# mean \n",
    "print('Mean similarity score of conflict edges: ', np.mean([x[2] for x in conflict_similarities]))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Measures"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conflict graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in degree\n",
    "in_deg_conflicts = dict(G_conflicts.in_degree())\n",
    "in_deg_conflicts = {k: v for k, v in sorted(in_deg_conflicts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# out degree\n",
    "out_deg_conflicts = dict(G_conflicts.out_degree())\n",
    "out_deg_conflicts = {k: v for k, v in sorted(out_deg_conflicts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# closeness centrality\n",
    "closeness_conflicts = nx.closeness_centrality(G_conflicts)\n",
    "closeness_conflicts = {k: v for k, v in sorted(closeness_conflicts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# betweenness centrality\n",
    "betweenness_conflicts = nx.betweenness_centrality(G_conflicts)\n",
    "betweenness_conflicts = {k: v for k, v in sorted(betweenness_conflicts.items(), key=lambda item: item[1], reverse=True)}\n",
    "\n",
    "# eigenvector centrality\n",
    "eigenvector_conflicts = nx.eigenvector_centrality(G_conflicts)\n",
    "eigenvector_conflicts = {k: v for k, v in sorted(eigenvector_conflicts.items(), key=lambda item: item[1], reverse=True)}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Full graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_full = nx.closeness_centrality(G)\n",
    "betweenness_full = nx.betweenness_centrality(G)\n",
    "eigenvector_full = nx.eigenvector_centrality(G)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_neg = nx.closeness_centrality(G_neg)\n",
    "betweenness_neg = nx.betweenness_centrality(G_neg)\n",
    "eigenvector_neg = nx.eigenvector_centrality(G_neg)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closeness_pos = nx.closeness_centrality(G_pos)\n",
    "betweenness_pos = nx.betweenness_centrality(G_pos)\n",
    "eigenvector_pos = nx.eigenvector_centrality(G_pos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(closeness_conflicts, orient='index').to_csv('results/closeness_conflicts.csv')\n",
    "pd.DataFrame.from_dict(betweenness_conflicts, orient='index').to_csv('results/betweenness_conflicts.csv')\n",
    "pd.DataFrame.from_dict(eigenvector_conflicts, orient='index').to_csv('results/eigenvector_conflicts.csv')\n",
    "\n",
    "pd.DataFrame.from_dict(closeness_full, orient='index').to_csv('results/closeness_full.csv')\n",
    "pd.DataFrame.from_dict(betweenness_full, orient='index').to_csv('results/betweenness_full.csv')\n",
    "pd.DataFrame.from_dict(eigenvector_full, orient='index').to_csv('results/eigenvector_full.csv')\n",
    "\n",
    "pd.DataFrame.from_dict(closeness_neg, orient='index').to_csv('results/closeness_neg.csv')\n",
    "pd.DataFrame.from_dict(betweenness_neg, orient='index').to_csv('results/betweenness_neg.csv')\n",
    "pd.DataFrame.from_dict(eigenvector_neg, orient='index').to_csv('results/eigenvector_neg.csv')\n",
    "\n",
    "pd.DataFrame.from_dict(closeness_pos, orient='index').to_csv('results/closeness_pos.csv')\n",
    "pd.DataFrame.from_dict(betweenness_pos, orient='index').to_csv('results/betweenness_pos.csv')\n",
    "pd.DataFrame.from_dict(eigenvector_pos, orient='index').to_csv('results/eigenvector_pos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity score in graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity score of full graph:  0.2874672526046712\n"
     ]
    }
   ],
   "source": [
    "# similarity score of full graph\n",
    "r_grouped = r.groupby(['SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT']).size().reset_index(name='counts')\n",
    "r_grouped[\"SIMILARITY\"] = r_grouped.apply(lambda x: similarity_score(x[\"SOURCE_SUBREDDIT\"], x[\"TARGET_SUBREDDIT\"]), axis=1)\n",
    "r_grouped = r_grouped.dropna()\n",
    "\n",
    "print('Mean similarity score of full graph: ', np.mean(r_grouped[\"SIMILARITY\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity score of negative graph:  0.3020378108951983\n"
     ]
    }
   ],
   "source": [
    "# similarity score of negative graph\n",
    "r_neg_grouped = r_neg.groupby(['SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT']).size().reset_index(name='counts')\n",
    "r_neg_grouped[\"SIMILARITY\"] = r_neg_grouped.apply(lambda x: similarity_score(x[\"SOURCE_SUBREDDIT\"], x[\"TARGET_SUBREDDIT\"]), axis=1)\n",
    "r_neg_grouped = r_neg_grouped.dropna()\n",
    "\n",
    "print('Mean similarity score of negative graph: ', np.mean(r_neg_grouped[\"SIMILARITY\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity score of positive graph:  0.28979982991020664\n"
     ]
    }
   ],
   "source": [
    "# similarity score of positive graph\n",
    "r_pos_grouped = r_pos.groupby(['SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT']).size().reset_index(name='counts')\n",
    "r_pos_grouped[\"SIMILARITY\"] = r_pos_grouped.apply(lambda x: similarity_score(x[\"SOURCE_SUBREDDIT\"], x[\"TARGET_SUBREDDIT\"]), axis=1)\n",
    "r_pos_grouped = r_pos_grouped.dropna()\n",
    "\n",
    "print('Mean similarity score of positive graph: ', np.mean(r_pos_grouped[\"SIMILARITY\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean similarity score of negative graph:  0.35427542834280273\n"
     ]
    }
   ],
   "source": [
    "# similarity score of conflict graph\n",
    "r_conflict_grouped = r_neg.groupby(['SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT']).size().reset_index(name='counts')\n",
    "r_conflict_grouped[\"SIMILARITY\"] = r_conflict_grouped.apply(lambda x: similarity_score(x[\"SOURCE_SUBREDDIT\"], x[\"TARGET_SUBREDDIT\"]), axis=1)\n",
    "r_conflict_grouped = r_conflict_grouped.dropna()\n",
    "r_conflict_grouped = r_conflict_grouped[r_conflict_grouped[\"counts\"] > 9]\n",
    "\n",
    "print('Mean similarity score of negative graph: ',\n",
    "      np.mean(r_conflict_grouped[\"SIMILARITY\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 1 is out of bounds for axis 1 with size 1",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[58], line 14\u001b[0m\n\u001b[1;32m     11\u001b[0m tsne_scores \u001b[39m=\u001b[39m tsne\u001b[39m.\u001b[39mfit_transform(similarity_scores)\n\u001b[1;32m     13\u001b[0m \u001b[39m# Plot the results\u001b[39;00m\n\u001b[0;32m---> 14\u001b[0m plt\u001b[39m.\u001b[39mscatter(tsne_scores[:, \u001b[39m0\u001b[39m], tsne_scores[:, \u001b[39m1\u001b[39;49m])\n\u001b[1;32m     15\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39m'\u001b[39m\u001b[39mt-SNE plot of subreddit similarity scores\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     16\u001b[0m plt\u001b[39m.\u001b[39mxlabel(\u001b[39m'\u001b[39m\u001b[39mt-SNE dimension 1\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 1 is out of bounds for axis 1 with size 1"
     ]
    }
   ],
   "source": [
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# Load your dataframe\n",
    "df = r_conflict_grouped\n",
    "\n",
    "# Create a 2D array of similarity scores\n",
    "similarity_scores = np.array(df['SIMILARITY']).reshape(-1, 1)\n",
    "\n",
    "# Perform t-SNE to reduce the dimensionality of your data\n",
    "tsne = TSNE(n_components=2, random_state=42)\n",
    "tsne_scores = tsne.fit_transform(similarity_scores)\n",
    "\n",
    "# Plot the results\n",
    "plt.scatter(tsne_scores[:, 0], tsne_scores[:, 1])\n",
    "plt.title('t-SNE plot of subreddit similarity scores')\n",
    "plt.xlabel('t-SNE dimension 1')\n",
    "plt.ylabel('t-SNE dimension 2')\n",
    "plt.show()\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "08eac26dc1f80337b7d87e94e7159a5bad95c2e85f47efef91c61359b3afbfe9"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
