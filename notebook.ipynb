{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_source_target(source, sentiment):\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    df = source[['SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT']]\n",
    "\n",
    "    # count total number of link_sentiment == sentiment for each subreddit\n",
    "    df.insert(2,'TOTAL_LINK',source.groupby(['SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT'])[\n",
    "        'LINK_SENTIMENT'].transform(lambda x: (x == sentiment).sum()))\n",
    "\n",
    "    # order dataframe by TOTAL_LINK DESC\n",
    "    df = df.sort_values(by=['TOTAL_LINK'], ascending=False)\n",
    "\n",
    "    return df\n",
    "\n",
    "def gen_source_sink_hub(sentiment_df):\n",
    "    r_body_source = pd.DataFrame()\n",
    "    r_body_target = pd.DataFrame()\n",
    "\n",
    "    # df con tutti i nodi sorgente  \n",
    "    r_body_source = sentiment_df['SOURCE_SUBREDDIT'] \n",
    "    # delete the duplicate\n",
    "    r_body_source = r_body_source.drop_duplicates()\n",
    "    # reset index\n",
    "    r_body_source = r_body_source.reset_index()\n",
    "    #print(\"Numero di sorgenti con negative sentiment: \",len(r_body_source))\n",
    "\n",
    "    # df con tutti i nodi target\n",
    "    r_body_target = sentiment_df['TARGET_SUBREDDIT']\n",
    "    # delete the duplicate\n",
    "    r_body_target = sentiment_df.drop_duplicates()\n",
    "    # reset index\n",
    "    r_body_target = r_body_target.reset_index()\n",
    "    #print(\"Numero di target con negative sentiment: \",len(r_body_target))\n",
    "\n",
    "    # build a df as difference between source and target\n",
    "    source = pd.DataFrame()\n",
    "    target = pd.DataFrame()\n",
    "    hub = pd.DataFrame()\n",
    "\n",
    "    #drop from r_body_source all element present in r_target\n",
    "    source = r_body_source[~r_body_source['SOURCE_SUBREDDIT'].isin(r_body_target['TARGET_SUBREDDIT'])]\n",
    "    #drop from r_body_target all element present in r_source\n",
    "    target = r_body_target[~r_body_target['TARGET_SUBREDDIT'].isin(r_body_source['SOURCE_SUBREDDIT'])]\n",
    "\n",
    "    # insert in hub all element of r_body_source\n",
    "    hub = pd.concat([r_body_source,r_body_target])\n",
    "    # drop all duplicate\n",
    "    hub = hub.drop_duplicates()\n",
    "    # remove all element present in source\n",
    "    hub = hub[~hub['SOURCE_SUBREDDIT'].isin(source['SOURCE_SUBREDDIT'])]\n",
    "    # remove all element present in target\n",
    "    hub = hub[~hub['TARGET_SUBREDDIT'].isin(target['TARGET_SUBREDDIT'])]\n",
    "    # reset index\n",
    "    hub = hub.reset_index()\n",
    "\n",
    "    return source,target,hub\n",
    "\n",
    "\n",
    "def gen_graph(df):\n",
    "    # Create graph\n",
    "    G = nx.from_pandas_edgelist(df, 'SOURCE_SUBREDDIT', 'TARGET_SUBREDDIT',edge_attr='TOTAL_LINK', create_using=nx.DiGraph())\n",
    "\n",
    "    # Remove self-loop\n",
    "    G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "    # Remove nodes with degree 0\n",
    "    G.remove_nodes_from(list(nx.isolates(G)))\n",
    "\n",
    "    return G\n",
    "\n",
    "\n",
    "def gen_plot(G, title):\n",
    "    # Set layout\n",
    "    pos = nx.spring_layout(G, k=0.1, iterations=20)\n",
    "\n",
    "    # Set node size\n",
    "    node_size = [G.degree(v) * 10 for v in G]\n",
    "\n",
    "    # Set node color\n",
    "    node_color = [G.degree(v) for v in G]\n",
    "\n",
    "    # Set edge width\n",
    "    #edge_width = [d['TOTAL_LINK'] / 5 for (u, v, d) in G.edges(data=True)]\n",
    "\n",
    "    # Set node label\n",
    "    node_label = {v: v for v in G}\n",
    "\n",
    "    # Set edge label\n",
    "    edge_label = {(u, v): d['TOTAL_LINK'] for (u, v, d) in G.edges(data=True)}\n",
    "\n",
    "    # Set colormap\n",
    "    cmap = plt.cm.get_cmap('viridis_r')\n",
    "\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=(20, 20))\n",
    "\n",
    "    # Draw graph\n",
    "    nx.draw_networkx_nodes(G, pos, node_size=node_size,\n",
    "                           node_color=node_color, cmap=cmap)\n",
    "    nx.draw_networkx_edges(G, pos, width=1, edge_color='lightgray')\n",
    "    #nx.draw_networkx_labels(G, pos, labels=node_label, font_size=10)\n",
    "    nx.draw_networkx_edge_labels(G, pos, edge_labels=edge_label, font_size=8)\n",
    "\n",
    "    # Set title\n",
    "    plt.title(title, fontsize=20)\n",
    "\n",
    "    # Set colorbar\n",
    "    sm = plt.cm.ScalarMappable(\n",
    "        cmap=cmap, norm=plt.Normalize(vmin=0, vmax=max(node_color)))\n",
    "    sm._A = []\n",
    "    plt.colorbar(sm)\n",
    "\n",
    "    # Show plot\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "def statistics(df):\n",
    "    # make mean of all the counts\n",
    "    mean = df['TOTAL_LINK'].mean()\n",
    "\n",
    "    # make median of all the counts\n",
    "    median = df['TOTAL_LINK'].median()\n",
    "\n",
    "    # make standard deviation of all the counts\n",
    "    std = df['TOTAL_LINK'].std()\n",
    "\n",
    "    # make variance of all the counts\n",
    "    var = df['TOTAL_LINK'].var()\n",
    "\n",
    "    # make max of all the counts\n",
    "    max = df['TOTAL_LINK'].max()\n",
    "\n",
    "    # make min of all the counts\n",
    "    min = df['TOTAL_LINK'].min()\n",
    "\n",
    "    # make sum of all the counts\n",
    "    sum = df['TOTAL_LINK'].sum()\n",
    "\n",
    "    # make count of all the counts\n",
    "    count = df['TOTAL_LINK'].count()\n",
    "\n",
    "    # make mode of all the counts\n",
    "    mode = df['TOTAL_LINK'].mode()\n",
    "\n",
    "    # count all element of r where count > 10\n",
    "    # !516\n",
    "    r_max10 = df[df['TOTAL_LINK'] > 10].count()\n",
    "\n",
    "    # !5659\n",
    "    r_min_eq_10 = df[df['TOTAL_LINK'] <= 10].count()\n",
    "\n",
    "    # print all as table\n",
    "    print('mean: ', mean)\n",
    "    print('median: ', median)\n",
    "    print('std: ', std)\n",
    "    print('var: ', var)\n",
    "    print('max: ', max)\n",
    "    print('min: ', min)\n",
    "    print('sum: ', sum)\n",
    "    print('count: ', count)\n",
    "    print('mode: ', mode)\n",
    "    print('r_max10: ', r_max10)\n",
    "    print('r_min10: ', r_min_eq_10)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read tsv file\n",
    "r_body = pd.read_csv('soc-redditHyperlinks-body.tsv', sep='\\t')\n",
    "r_title = pd.read_csv('soc-redditHyperlinks-title.tsv', sep='\\t')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dividiamo r_body ed r_title in link negativi e link positivi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_body_negative = r_body[r_body['LINK_SENTIMENT'] == -1]\n",
    "r_body_positive = r_body[r_body['LINK_SENTIMENT'] == 1]\n",
    "r_title_negative = r_title[r_title['LINK_SENTIMENT'] == -1]\n",
    "r_title_positive = r_title[r_title['LINK_SENTIMENT'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "************************REDDIT WITH NEGATIVE SENTIMENT*******************************\n",
      "\n",
      "\n",
      "       SOURCE_SUBREDDIT      TARGET_SUBREDDIT POST_ID            TIMESTAMP  \\\n",
      "1            theredlion                soccer  1u4qkd  2013-12-31 18:18:37   \n",
      "34      karmaconspiracy                 funny  1u6fz3  2014-01-01 12:44:19   \n",
      "43             badkarma              gamesell  1u6t4g  2014-01-01 16:42:14   \n",
      "53           casualiama             teenagers  1u70s8  2014-01-01 17:09:46   \n",
      "55            australia                sydney  1u71zd  2014-01-01 17:24:46   \n",
      "...                 ...                   ...     ...                  ...   \n",
      "286475      badpolitics  bannedfromthe_donald  68h72b  2017-04-30 11:57:36   \n",
      "286491    tipofmytongue             deathcore  68hbx9  2017-04-30 12:34:09   \n",
      "286501       soundcloud                procss  68hi5v  2017-04-30 12:16:13   \n",
      "286523  enoughtrumpspam       humansbeingbros  68hxu6  2017-04-30 14:25:18   \n",
      "286554   subredditdrama                 funny  68iigy  2017-04-30 16:05:45   \n",
      "\n",
      "        LINK_SENTIMENT                                         PROPERTIES  \n",
      "1                   -1  101.0,98.0,0.742574257426,0.019801980198,0.049...  \n",
      "34                  -1  186.0,182.0,0.741935483871,0.0376344086022,0.0...  \n",
      "43                  -1  262.0,258.0,0.725190839695,0.0381679389313,0.0...  \n",
      "53                  -1  91.0,91.0,0.78021978022,0.032967032967,0.04395...  \n",
      "55                  -1  2547.0,2158.0,0.801334903808,0.0051040439733,0...  \n",
      "...                ...                                                ...  \n",
      "286475              -1  641.0,553.0,0.808112324493,0.00780031201248,0....  \n",
      "286491              -1  2439.0,2016.0,0.754817548175,0.0069700697007,0...  \n",
      "286501              -1  1053.0,912.0,0.764482431149,0.00569800569801,0...  \n",
      "286523              -1  114.0,114.0,0.701754385965,0.0789473684211,0.0...  \n",
      "286554              -1  345.0,305.0,0.747826086957,0.0173913043478,0.0...  \n",
      "\n",
      "[21070 rows x 6 columns]\n",
      "\n",
      "\n",
      "************************REDDIT WITH POSITIVE SENTIMENT*******************************\n",
      "\n",
      "\n",
      "           SOURCE_SUBREDDIT   TARGET_SUBREDDIT  POST_ID            TIMESTAMP  \\\n",
      "0           leagueoflegends    teamredditteams  1u4nrps  2013-12-31 16:39:58   \n",
      "2              inlandempire             bikela  1u4qlzs  2014-01-01 14:54:35   \n",
      "3                       nfl                cfb  1u4sjvs  2013-12-31 17:37:55   \n",
      "4                playmygame            gamedev  1u4w5ss  2014-01-01 02:51:13   \n",
      "5                dogemarket           dogecoin  1u4w7bs  2013-12-31 18:35:44   \n",
      "...                     ...                ...      ...                  ...   \n",
      "286556           negareddit      debatefascism  68im20s  2017-04-30 16:31:26   \n",
      "286557          mildlynomil          justnomil  68imlas  2017-04-30 04:19:03   \n",
      "286558               mmorpg  blackdesertonline  68ip5os  2017-04-30 16:54:08   \n",
      "286559  electricskateboards          askreddit  68ipb2s  2017-04-30 16:41:53   \n",
      "286560                mgtow    dataisbeautiful  68ipeos  2017-04-30 16:52:59   \n",
      "\n",
      "        LINK_SENTIMENT                                         PROPERTIES  \n",
      "0                    1  345.0,298.0,0.75652173913,0.0173913043478,0.08...  \n",
      "2                    1  85.0,85.0,0.752941176471,0.0235294117647,0.082...  \n",
      "3                    1  1124.0,949.0,0.772241992883,0.0017793594306,0....  \n",
      "4                    1  715.0,622.0,0.777622377622,0.00699300699301,0....  \n",
      "5                    1  1328.0,1110.0,0.768825301205,0.0143072289157,0...  \n",
      "...                ...                                                ...  \n",
      "286556               1  441.0,405.0,0.775510204082,0.0294784580499,0.0...  \n",
      "286557               1  2226.0,1855.0,0.786163522013,0.00224618149146,...  \n",
      "286558               1  1100.0,909.0,0.778181818182,0.00181818181818,0...  \n",
      "286559               1  1876.0,1567.0,0.78144989339,0.00692963752665,0...  \n",
      "286560               1  1129.0,975.0,0.795394154119,0.0150575730735,0....  \n",
      "\n",
      "[265491 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "print(\"************************REDDIT WITH NEGATIVE SENTIMENT*******************************\\n\\n\")\n",
    "print(r_body_negative)\n",
    "print(\"\\n\\n************************REDDIT WITH POSITIVE SENTIMENT*******************************\\n\\n\")\n",
    "print(r_body_positive)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generiamo tutte le coppie sorgente - target. Per ogni coppia teniamo traccia del numero totali di interazioni con il target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df with all couple SOURCE TARGET with positive sentiment\n",
    "reddit_positive = df_source_target(r_body_positive, 1)\n",
    "\n",
    "# df with all couple SOURCE TARGET with negative sentiment\n",
    "reddit_negative = df_source_target(r_body_negative, -1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21070\n",
      "265491\n"
     ]
    }
   ],
   "source": [
    "print(len(reddit_negative))\n",
    "print(len(reddit_positive))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### In the context of a network, a _Hub_ is a node with a large degree, meaning it has connections with many other nodes. A node is considered a *Source* in a graph if it has in-degree of 0 (no nodes have a source as their destination); likewise, a node is considered a _Sink_ in a graph if it has out-degree of 0 (no nodes have a sink as their source)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_negative,sink_negative,hub_negative = gen_source_sink_hub(r_body_negative)\n",
    "source_positive,sink_positive,hub_positive = gen_source_sink_hub(r_body_positive)\n",
    "\n",
    "# # check if element in source are in target\n",
    "# print(source_negative[source_negative['SOURCE_SUBREDDIT'].isin(target_negative['TARGET_SUBREDDIT'])])\n",
    "\n",
    "# # check if element in target are in source\n",
    "# print(target_negative[target_negative['TARGET_SUBREDDIT'].isin(source_negative['SOURCE_SUBREDDIT'])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numero di nodi source con negative sentiment:  2463\n",
      "Numero di nodi sink con negative sentiment:  6538\n",
      "Numero di nodi hub con negative sentiment:  13269\n",
      "Numero di nodi source con positive sentiment:  14895\n",
      "Numero di nodi sink con positive sentiment:  25716\n",
      "Numero di nodi hub con positive sentiment:  222950\n"
     ]
    }
   ],
   "source": [
    "print(\"Numero di nodi source con negative sentiment: \",len(source_negative))\n",
    "print(\"Numero di nodi sink con negative sentiment: \",len(sink_negative))\n",
    "print(\"Numero di nodi hub con negative sentiment: \",len(hub_negative))\n",
    "\n",
    "print(\"Numero di nodi source con positive sentiment: \",len(source_positive))\n",
    "print(\"Numero di nodi sink con positive sentiment: \",len(sink_positive))\n",
    "print(\"Numero di nodi hub con positive sentiment: \",len(hub_positive))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<pandas.core.groupby.generic.SeriesGroupBy object at 0x7fc99067db70>\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>SOURCE_SUBREDDIT</th>\n",
       "      <th>TARGET_SUBREDDIT</th>\n",
       "      <th>TOTAL_LINK</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8028</th>\n",
       "      <td>circloljerk</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40790</th>\n",
       "      <td>circloljerk</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78916</th>\n",
       "      <td>circloljerk</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69955</th>\n",
       "      <td>circloljerk</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79474</th>\n",
       "      <td>circloljerk</td>\n",
       "      <td>leagueoflegends</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122616</th>\n",
       "      <td>botwatch</td>\n",
       "      <td>requestabot</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122634</th>\n",
       "      <td>stlouiscirclejerk</td>\n",
       "      <td>stlouis</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122692</th>\n",
       "      <td>casualpokemontrades</td>\n",
       "      <td>pokemonplaza</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122707</th>\n",
       "      <td>compulsiveskinpicking</td>\n",
       "      <td>todayilearned</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>122784</th>\n",
       "      <td>shrekislove</td>\n",
       "      <td>jontron</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4427 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             SOURCE_SUBREDDIT TARGET_SUBREDDIT  TOTAL_LINK\n",
       "8028              circloljerk  leagueoflegends          30\n",
       "40790             circloljerk  leagueoflegends          30\n",
       "78916             circloljerk  leagueoflegends          30\n",
       "69955             circloljerk  leagueoflegends          30\n",
       "79474             circloljerk  leagueoflegends          30\n",
       "...                       ...              ...         ...\n",
       "122616               botwatch      requestabot           1\n",
       "122634      stlouiscirclejerk          stlouis           1\n",
       "122692    casualpokemontrades     pokemonplaza           1\n",
       "122707  compulsiveskinpicking    todayilearned           1\n",
       "122784            shrekislove          jontron           1\n",
       "\n",
       "[4427 rows x 3 columns]"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "source_negative_2 = reddit_negative[reddit_negative['SOURCE_SUBREDDIT'].isin(source_negative['SOURCE_SUBREDDIT'])]\n",
    "\n",
    "print(source_negative_2.groupby(['SOURCE_SUBREDDIT','TARGET_SUBREDDIT'])['SOURCE_SUBREDDIT'])\n",
    "\n",
    "source_negative_2"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statistics(reddit_negative)\n",
    "# statistics(reddit_positive)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Graph visualization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Negative sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_negative = gen_graph(reddit_negative[reddit_negative['TOTAL_LINK'] > 10])\n",
    "gen_plot(G_negative, 'negative sentiment')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "G_positive = gen_graph(reddit_positive[reddit_positive['TOTAL_LINK'] > 10])\n",
    "gen_plot(G_positive, 'positive sentiment')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rows where link_sentiment is -1 (negative) and group by subreddit and count the number of rows\n",
    "r = r_body[r_body['LINK_SENTIMENT'] == -1].groupby('SOURCE_SUBREDDIT')['LINK_SENTIMENT'].count()\n",
    "\n",
    "# order by count\n",
    "r = r.sort_values(ascending=False)\n",
    "r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# show rows where link_sentiment is -1 (negative) and group by subreddit and count the number of rows\n",
    "r = r_title[r_title['LINK_SENTIMENT'] == -1].groupby('SOURCE_SUBREDDIT')['LINK_SENTIMENT'].count()\n",
    "\n",
    "# order by count\n",
    "r = r.sort_values(ascending=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "24c615f1cd05200abc6f932b8e67c5e5aeb8a2a58b935025ad22ca9df46b75fe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
